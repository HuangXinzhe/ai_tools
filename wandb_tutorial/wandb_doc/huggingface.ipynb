{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 详细介绍请查看官方文档\n",
    "https://docs.wandb.ai/guides/integrations/huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在使用huggingface transformers进行大模型微调中使用wandb进行实验记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需要设置的内容主要是相关环境变量与参数\n",
    "import os\n",
    "from transformers import TrainingArguments, Trainer\n",
    "os.environ[\"WANDB_PROJECT\"] = \"<my-amazing-project>\"  # name your W&B project\n",
    "os.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\"  # log all model checkpoints\n",
    "\n",
    "\n",
    "args = TrainingArguments(..., report_to=\"wandb\")  # turn on W&B logging\n",
    "trainer = Trainer(..., args=args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 以下是具体的使用方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 登录wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "# import os\n",
    "# os.environ[\"WANDB_API_KEY\"] = \"xxx\"\n",
    "wandb.login()\n",
    "\n",
    "# 可以设置wandb的key环境变量登录"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 给wandb设置项目名称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_PROJECT\"] = \"xxx\"\n",
    "# 没有指定则默认为huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过report_to参数设置是否上传到wandb\n",
    "# 通过run_name参数设置上传的名称\n",
    "# 通过logging_steps参数设置上传的频率\n",
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "args = TrainingArguments(\n",
    "    # other args and kwargs here\n",
    "    report_to=\"wandb\",  # enable logging to W&B\n",
    "    run_name=\"bert-base-high-lr\",  # name of the W&B run (optional)\n",
    "    logging_steps=1,  # how often to log to W&B\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    # other args and kwargs here\n",
    "    args=args,  # your training args\n",
    ")\n",
    "\n",
    "trainer.train()  # start training and logging to W&B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 上传模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 共两个参数可以选择：checkpoint和end\n",
    "# checkpoint：上传TrainingArguments中每个args.save_steps\n",
    "# end：训练结束后上传\n",
    "# https://docs.wandb.ai/guides/model_registry\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 模型训练后可视化评估输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.wandb.ai/guides/integrations/huggingface#custom-logging-log-and-view-evaluation-samples-during-training\n",
    "run.summary[\"article_topics_extract\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 结束wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果是使用jupyter或者Google Colab\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. 可视化结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.wandb.ai/guides/track/app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 高级功能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存最好的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在TrainingArguments中设置load_best_model_at_end=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载保存的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new run\n",
    "with wandb.init(project=\"amazon_sentiment_analysis\") as run:\n",
    "    # Pass the name and version of Artifact\n",
    "    my_model_name = \"model-bert-base-high-lr:latest\"\n",
    "    my_model_artifact = run.use_artifact(my_model_name)\n",
    "\n",
    "    # Download model weights to a folder and return the path\n",
    "    model_dir = my_model_artifact.download()\n",
    "\n",
    "    # Load your Hugging Face model from that folder\n",
    "    #  using the same model class\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_dir, num_labels=num_labels\n",
    "    )\n",
    "\n",
    "    # Do additional training, or run inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从一个checkpoint继续训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_run_id = \"xxxxxxxx\"  # fetch the run_id from your wandb workspace\n",
    "\n",
    "# resume the wandb run from the run_id\n",
    "with wandb.init(\n",
    "    project=os.environ[\"WANDB_PROJECT\"],\n",
    "    id=last_run_id,\n",
    "    resume=\"must\",\n",
    ") as run:\n",
    "    # Connect an Artifact to the run\n",
    "    my_checkpoint_name = f\"checkpoint-{last_run_id}:latest\"\n",
    "    my_checkpoint_artifact = run.use_artifact(my_model_name)\n",
    "\n",
    "    # Download checkpoint to a folder and return the path\n",
    "    checkpoint_dir = my_checkpoint_artifact.download()\n",
    "\n",
    "    # reinitialize your model and trainer\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"<model_name>\", num_labels=num_labels\n",
    "    )\n",
    "    # your awesome training arguments here.\n",
    "    training_args = TrainingArguments()\n",
    "\n",
    "    trainer = Trainer(model=model, args=training_args)\n",
    "\n",
    "    # make sure use the checkpoint dir to resume training from the checkpoint\n",
    "    trainer.train(resume_from_checkpoint=checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自定义初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"amazon_sentiment_analysis\",\n",
    "    name=\"bert-base-high-lr\",\n",
    "    tags=[\"baseline\", \"high-lr\"],\n",
    "    group=\"bert\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在训练中记录和观察评估样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Trainer as normal\n",
    "trainer = Trainer()\n",
    "\n",
    "# Instantiate the new logging callback, passing it the Trainer object\n",
    "evals_callback = WandbEvalsCallback(trainer, tokenizer, ...)\n",
    "\n",
    "# Add the callback to the Trainer\n",
    "trainer.add_callback(evals_callback)\n",
    "\n",
    "# Begin Trainer training as normal\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在训练中查看评估样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.integrations import WandbCallback\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def decode_predictions(tokenizer, predictions):\n",
    "    labels = tokenizer.batch_decode(predictions.label_ids)\n",
    "    logits = predictions.predictions.argmax(axis=-1)\n",
    "    prediction_text = tokenizer.batch_decode(logits)\n",
    "    return {\"labels\": labels, \"predictions\": prediction_text}\n",
    "\n",
    "\n",
    "class WandbPredictionProgressCallback(WandbCallback):\n",
    "    \"\"\"Custom WandbCallback to log model predictions during training.\n",
    "\n",
    "    This callback logs model predictions and labels to a wandb.Table at each \n",
    "    logging step during training. It allows to visualize the \n",
    "    model predictions as the training progresses.\n",
    "\n",
    "    Attributes:\n",
    "        trainer (Trainer): The Hugging Face Trainer instance.\n",
    "        tokenizer (AutoTokenizer): The tokenizer associated with the model.\n",
    "        sample_dataset (Dataset): A subset of the validation dataset \n",
    "          for generating predictions.\n",
    "        num_samples (int, optional): Number of samples to select from \n",
    "          the validation dataset for generating predictions. Defaults to 100.\n",
    "        freq (int, optional): Frequency of logging. Defaults to 2.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, trainer, tokenizer, val_dataset,\n",
    "                 num_samples=100, freq=2):\n",
    "        \"\"\"Initializes the WandbPredictionProgressCallback instance.\n",
    "\n",
    "        Args:\n",
    "            trainer (Trainer): The Hugging Face Trainer instance.\n",
    "            tokenizer (AutoTokenizer): The tokenizer associated \n",
    "              with the model.\n",
    "            val_dataset (Dataset): The validation dataset.\n",
    "            num_samples (int, optional): Number of samples to select from \n",
    "              the validation dataset for generating predictions.\n",
    "              Defaults to 100.\n",
    "            freq (int, optional): Frequency of logging. Defaults to 2.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.trainer = trainer\n",
    "        self.tokenizer = tokenizer\n",
    "        self.sample_dataset = val_dataset.select(range(num_samples))\n",
    "        self.freq = freq\n",
    "\n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        super().on_evaluate(args, state, control, **kwargs)\n",
    "        # control the frequency of logging by logging the predictions\n",
    "        # every `freq` epochs\n",
    "        if state.epoch % self.freq == 0:\n",
    "            # generate predictions\n",
    "            predictions = self.trainer.predict(self.sample_dataset)\n",
    "            # decode predictions and labels\n",
    "            predictions = decode_predictions(self.tokenizer, predictions)\n",
    "            # add predictions to a wandb.Table\n",
    "            predictions_df = pd.DataFrame(predictions)\n",
    "            predictions_df[\"epoch\"] = state.epoch\n",
    "            records_table = self._wandb.Table(dataframe=predictions_df)\n",
    "            # log the table to wandb\n",
    "            self._wandb.log({\"sample_predictions\": records_table})\n",
    "\n",
    "\n",
    "# First, instantiate the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_datasets[\"train\"],\n",
    "    eval_dataset=lm_datasets[\"validation\"],\n",
    ")\n",
    "\n",
    "# Instantiate the WandbPredictionProgressCallback\n",
    "progress_callback = WandbPredictionProgressCallback(\n",
    "    trainer=trainer,\n",
    "    tokenizer=tokenizer,\n",
    "    val_dataset=lm_dataset[\"validation\"],\n",
    "    num_samples=10,\n",
    "    freq=2,\n",
    ")\n",
    "\n",
    "# Add the callback to the trainer\n",
    "trainer.add_callback(progress_callback)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
