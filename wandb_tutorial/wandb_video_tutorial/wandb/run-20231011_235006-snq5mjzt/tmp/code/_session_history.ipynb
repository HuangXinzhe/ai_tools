{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08e98b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save code \n",
    "\n",
    "arti_code = wandb.Artifact('ipynb', type='code')\n",
    "arti_code.add_file('./30ÂàÜÈíüÂêÉÊéâwandbÂèØËßÜÂåñÊ®°ÂûãÂàÜÊûê.ipynb')\n",
    "wandb.log_artifact(arti_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a45e1e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "# import os\n",
    "# os.environ[\"WANDB_API_KEY\"] = \"xxx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ae459bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,PIL \n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch \n",
    "from torch import nn \n",
    "import torchvision \n",
    "from torchvision import transforms\n",
    "import datetime\n",
    "import wandb \n",
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6615215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpuÈÄâÊã©\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('mps' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0123b5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÈÖçÁΩÆ\n",
    "config = Namespace(\n",
    "    project_name = 'wandb_demo',\n",
    "    \n",
    "    batch_size = 512,\n",
    "    \n",
    "    hidden_layer_width = 64,\n",
    "    dropout_p = 0.1,\n",
    "    \n",
    "    lr = 1e-4,\n",
    "    optim_type = 'Adam',\n",
    "    \n",
    "    epochs = 15,\n",
    "    ckpt_path = 'checkpoint.pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8550c79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Êï∞ÊçÆÈõÜ\n",
    "def create_dataloaders(config):\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    ds_train = torchvision.datasets.MNIST(root=\"./mnist/\",train=True,download=True,transform=transform)\n",
    "    ds_val = torchvision.datasets.MNIST(root=\"./mnist/\",train=False,download=True,transform=transform)\n",
    "\n",
    "    ds_train_sub = torch.utils.data.Subset(ds_train, indices=range(0, len(ds_train), 5))\n",
    "    dl_train =  torch.utils.data.DataLoader(ds_train_sub, batch_size=config.batch_size, shuffle=True,\n",
    "                                            num_workers=2,drop_last=True)\n",
    "    dl_val =  torch.utils.data.DataLoader(ds_val, batch_size=config.batch_size, shuffle=False, \n",
    "                                          num_workers=2,drop_last=True)\n",
    "    return dl_train,dl_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27bff62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ê®°ÂûãÁªìÊûÑ\n",
    "def create_net(config):\n",
    "    net = nn.Sequential()\n",
    "    net.add_module(\"conv1\",nn.Conv2d(in_channels=1,out_channels=config.hidden_layer_width,kernel_size = 3))\n",
    "    net.add_module(\"pool1\",nn.MaxPool2d(kernel_size = 2,stride = 2)) \n",
    "    net.add_module(\"conv2\",nn.Conv2d(in_channels=config.hidden_layer_width,\n",
    "                                     out_channels=config.hidden_layer_width,kernel_size = 5))\n",
    "    net.add_module(\"pool2\",nn.MaxPool2d(kernel_size = 2,stride = 2))\n",
    "    net.add_module(\"dropout\",nn.Dropout2d(p = config.dropout_p))\n",
    "    net.add_module(\"adaptive_pool\",nn.AdaptiveMaxPool2d((1,1)))\n",
    "    net.add_module(\"flatten\",nn.Flatten())\n",
    "    net.add_module(\"linear1\",nn.Linear(config.hidden_layer_width,config.hidden_layer_width))\n",
    "    net.add_module(\"relu\",nn.ReLU())\n",
    "    net.add_module(\"linear2\",nn.Linear(config.hidden_layer_width,10))\n",
    "    net.to(device)\n",
    "    return net "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2417002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model,dl_train,optimizer):\n",
    "    model.train()\n",
    "    for step, batch in enumerate(dl_train):\n",
    "        features,labels = batch\n",
    "        features,labels = features.to(device),labels.to(device)\n",
    "\n",
    "        preds = model(features)\n",
    "        loss = nn.CrossEntropyLoss()(preds,labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9004672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_epoch(model,dl_val):\n",
    "    model.eval()\n",
    "    accurate = 0\n",
    "    num_elems = 0\n",
    "    for batch in dl_val:\n",
    "        features,labels = batch\n",
    "        features,labels = features.to(device),labels.to(device)\n",
    "        with torch.no_grad():\n",
    "            preds = model(features)\n",
    "        predictions = preds.argmax(dim=-1)\n",
    "        accurate_preds =  (predictions==labels)\n",
    "        num_elems += accurate_preds.shape[0]\n",
    "        accurate += accurate_preds.long().sum()\n",
    "\n",
    "    val_acc = accurate.item() / num_elems\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "578ab002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config = config):\n",
    "    dl_train, dl_val = create_dataloaders(config)\n",
    "    model = create_net(config); \n",
    "    optimizer = torch.optim.__dict__[config.optim_type](params=model.parameters(), lr=config.lr)\n",
    "    #======================================================================\n",
    "    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    wandb.init(project=config.project_name, config = config.__dict__, name = nowtime, save_code=True)\n",
    "    model.run_id = wandb.run.id\n",
    "    #======================================================================\n",
    "    model.best_metric = -1.0\n",
    "    for epoch in range(1,config.epochs+1):\n",
    "        model = train_epoch(model,dl_train,optimizer)\n",
    "        val_acc = eval_epoch(model,dl_val)\n",
    "        if val_acc>model.best_metric:\n",
    "            model.best_metric = val_acc\n",
    "            torch.save(model.state_dict(),config.ckpt_path)   \n",
    "        nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print(f\"epoch„Äê{epoch}„Äë@{nowtime} --> val_acc= {100 * val_acc:.2f}%\")\n",
    "        #======================================================================\n",
    "        wandb.log({'epoch':epoch, 'val_acc': val_acc, 'best_val_acc':model.best_metric})\n",
    "        #======================================================================        \n",
    "    #======================================================================\n",
    "    wandb.finish()\n",
    "    #======================================================================\n",
    "    return model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8baa33c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "848220def5f14413ae9e9c96b7d48c75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011167639822222223, max=1.0‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/huangxinzhe/code/ai_tools/wandb_tutorial/wandb_video_tutorial/wandb/run-20231011_235006-snq5mjzt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/550w/wandb_demo/runs/snq5mjzt' target=\"_blank\">2023-10-11 23:50:06</a></strong> to <a href='https://wandb.ai/550w/wandb_demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/550w/wandb_demo' target=\"_blank\">https://wandb.ai/550w/wandb_demo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/550w/wandb_demo/runs/snq5mjzt' target=\"_blank\">https://wandb.ai/550w/wandb_demo/runs/snq5mjzt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = train(config) ##3,2,1 ÁÇπÁÅ´üî•üî•"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
