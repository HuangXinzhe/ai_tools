{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9044cdec",
   "metadata": {},
   "source": [
    "# 快速开始"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c93044",
   "metadata": {},
   "source": [
    "## 1. 准备模型权重"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba53b409",
   "metadata": {},
   "source": [
    "### huggingface下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad6ed8b-4ee1-4d91-b43c-6976eeb39621",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U huggingface_hub\n",
    "\n",
    "# 拉取模型至 Shanghai_AI_Laboratory/internlm2-chat-7b\n",
    "!huggingface-cli download internlm/internlm2-chat-7b \\\n",
    "                            --local-dir Shanghai_AI_Laboratory/internlm2-chat-7b \\\n",
    "                            --local-dir-use-symlinks False \\\n",
    "                            --resume-download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08cbbc3",
   "metadata": {},
   "source": [
    "### modelscope下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49375c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U modelscope\n",
    "\n",
    "# 拉取模型至当前目录\n",
    "!python -c \"from modelscope import snapshot_download; snapshot_download('Shanghai_AI_Laboratory/internlm2-chat-7b', cache_dir='.')\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a17f7a",
   "metadata": {},
   "source": [
    "## 2. 准备微调数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe69082",
   "metadata": {},
   "source": [
    "### Huggingfacexiaz\n",
    "git clone https://huggingface.co/datasets/burkelibbey/colors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a1b3e2",
   "metadata": {},
   "source": [
    "### modelscope下载\n",
    "git clone https://www.modelscope.cn/datasets/fanqiNO1/colors.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508f736b",
   "metadata": {},
   "source": [
    "## 3. 准备配置文件\n",
    "复制一个配置文件到当前目录  \n",
    "xtuner copy-cfg internlm2_7b_qlora_colorist_e5 .  \n",
    "- 模型：internlm2_7b\n",
    "- 微调方法：qlora\n",
    "- 微调数据集：colorist\n",
    "- 训练轮次：5epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364d5a94",
   "metadata": {},
   "source": [
    "## 4. 修改配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eeccbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "#                          PART 1  Settings                           #\n",
    "#######################################################################\n",
    "# Model\n",
    "- pretrained_model_name_or_path = 'internlm/internlm2-7b'\n",
    "+ pretrained_model_name_or_path = './Shanghai_AI_Laboratory/internlm2-chat-7b'\n",
    "\n",
    "# Data\n",
    "- data_path = 'burkelibbey/colors'\n",
    "+ data_path = './colors/train.jsonl'\n",
    "- prompt_template = PROMPT_TEMPLATE.default\n",
    "+ prompt_template = PROMPT_TEMPLATE.internlm2_chat\n",
    "\n",
    "...\n",
    "#######################################################################\n",
    "#                      PART 3  Dataset & Dataloader                   #\n",
    "#######################################################################\n",
    "train_dataset = dict(\n",
    "    type=process_hf_dataset,\n",
    "-   dataset=dict(type=load_dataset, path=data_path),\n",
    "+   dataset=dict(type=load_dataset, path='json', data_files=dict(train=data_path)),\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=max_length,\n",
    "    dataset_map_fn=colors_map_fn,\n",
    "    template_map_fn=dict(\n",
    "        type=template_map_fn_factory, template=prompt_template),\n",
    "    remove_unused_columns=True,\n",
    "    shuffle_before_pack=True,\n",
    "    pack_to_max_length=pack_to_max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeb1f3d",
   "metadata": {},
   "source": [
    "## 5. 启动微调\n",
    "# 单机单卡\n",
    "xtuner train ./internlm2_7b_qlora_colorist_e5_copy.py\n",
    "# 单机多卡\n",
    "NPROC_PER_NODE=${GPU_NUM} xtuner train ./internlm2_7b_qlora_colorist_e5_copy.py\n",
    "# slurm 情况\n",
    "srun ${SRUN_ARGS} xtuner train ./internlm2_7b_qlora_colorist_e5_copy.py --launcher slurm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b2eb76",
   "metadata": {},
   "source": [
    "## 6. 模型转型\n",
    "训练获得的.pth文件转为huggingface格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f265496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建存放 hf 格式参数的目录\n",
    "mkdir work_dirs/internlm2_7b_qlora_colorist_e5_copy/iter_720_hf\n",
    "\n",
    "# 转换格式\n",
    "xtuner convert pth_to_hf internlm2_7b_qlora_colorist_e5_copy.py \\\n",
    "                            work_dirs/internlm2_7b_qlora_colorist_e5_copy/iter_720.pth \\\n",
    "                            work_dirs/internlm2_7b_qlora_colorist_e5_copy/iter_720_hf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da0b971",
   "metadata": {},
   "source": [
    "## 7. LoRA合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e39170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建存放合并后的参数的目录\n",
    "mkdir work_dirs/internlm2_7b_qlora_colorist_e5_copy/merged\n",
    "\n",
    "# 合并参数\n",
    "xtuner convert merge Shanghai_AI_Laboratory/internlm2-chat-7b \\\n",
    "                        work_dirs/internlm2_7b_qlora_colorist_e5_copy/iter_720_hf \\\n",
    "                        work_dirs/internlm2_7b_qlora_colorist_e5_copy/merged \\\n",
    "                        --max-shard-size 2GB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512271f5",
   "metadata": {},
   "source": [
    "## 8. 模型对话"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb06873",
   "metadata": {},
   "source": [
    "合并后模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c65c771",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtuner chat work_dirs/internlm2_7b_qlora_colorist_e5_copy/merged \\\n",
    "                --prompt-template internlm2_chat \\\n",
    "                --system-template colorist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df482c33",
   "metadata": {},
   "source": [
    "未合并模型，直接与 LLM + LoRA Adapter 进行对话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6348b174",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtuner chat Shanghai_AI_Laboratory/internlm2-chat-7b\n",
    "                --adapter work_dirs/internlm2_7b_qlora_colorist_e5_copy/iter_720_hf \\\n",
    "                --prompt-template internlm2_chat \\\n",
    "                --system-template colorist"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
